---
# Banner
banner:
  title: "Microservices Framework for LLMs"
  content: "Build, Train, and Manage Workflow Plugins using Micro LLM"
  # image: "/images/banner.png"
  image: "/images/sugar/workflow-dark-4.png"
  button:
    enable: false
    label: "Join Waitlist"
    link: "#"
  waitlist:
    enable: true

# Features
features:
  - title: "An Open Source Framework for Developer Teams"
    image: "/images/service-1.png"
    content: "Sugarcane AI provides a Microservices Framework for LLM-agnostic workflow plugin development, allowing developers to prioritize business logic over LLM selection, cost, and performance"
    bulletpoints:
      - "Workflow As a Service for Plugin Developers"
      - "Prompts As a Service for Prompt Developers"
      - "LLMs As a Service for Data Scientists"
      - "Open Marketpalce to Package, Share Reuse & Monetize task specific Prompt packages, Micro LLMs & Datasets"
    button:
      enable: false
      label: "Join Waitlist"
      link: "#"
    waitlist:
      enable: true

  - title: "Key Components of Framework!"
    image: "/images/sugar/prompt_packages-3.png"
    content: "Sugar Bakery"
    bulletpoints:
      - "Write workflows in few lines of code"
      - "No need to hardcode prompts in your code"
      # - ""
    button:
      enable: false
      label: "Join Waitlist"
      link: "https://github.com/zeon-studio/Sugarcane AI"
    waitlist:
      enable: true
    
  - title: "What are Prompt Packages?"
    image: "/images/sugar/prompt_packages-3.png"
    content: "A prompt package is a collection of prompt templates, dataset, and llm configuration that can be distributed as a unit of reusable prompt or functionality in the LLM ecosystem. A prompt template is tied to a specific LLM config for high accuracy"
    bulletpoints:
      - "Enables Package of prompts and share with teams"
      - "Can be distributed via API"
      - "Together with a Micro LLM, it can deliver exceptionally high performance."
    button:
      enable: false
      label: "Join Waitlist"
      link: "https://github.com/zeon-studio/Sugarcane AI"
    waitlist:
      enable: true

  - title: "What are Micro LLMs?"
    image: "/images/service-2.png"
    content: "Micro LLMs are smaller fine tuned model build on top of 3b/7b parameters and trained for task specific prompts, which can be used to automate workflows/plugins to ensure their reliability and accuracy"
    bulletpoints:
      - "Very High Accuracy for Task Specific Prompts"
      - "Low Cost for Pre finetune Prompts"
      - "Ulta Low Latency for response generation"
    button:
      enable: false
      label: "Join Waitlist"
      link: "#"
    waitlist:
      enable: true

  

  # - title: "The Top Reasons to Choose Astro for Your Next Project"
  #   image: "/images/service-2.png"
  #   content: "With Astro, you can build modern and content-focused websites without sacrificing performance or ease of use."
  #   bulletpoints:
  #     - "Instantly load static sites for better user experience and SEO."
  #     - "Intuitive syntax and support for popular frameworks make learning and using Astro a breeze."
  #     - "Use any front-end library or framework, or build custom components, for any project size."
  #     - "Built on cutting-edge technology to keep your projects up-to-date with the latest web standards."
  #   button:
  #     enable: false
  #     label: ""
  #     link: ""
---
